% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mplnFA.R
\name{MPLNFAClust}
\alias{MPLNFAClust}
\title{Clustering via Parsimonious Mixtures of MPLN Factor Analyzers Family}
\usage{
MPLNFAClust(
  dataset,
  membership = "none",
  gmin = 1,
  gmax = 3,
  pmin = 1,
  pmax = 2,
  initMethod = "kmeans",
  modelNames = "CCC",
  normalize = "Yes"
)
}
\arguments{
\item{dataset}{A dataset of class matrix and type integer such that
rows correspond to observations and columns correspond to variables.
The dataset have dimensions n x d, where n is the total number of
observations and d is the dimensionality. The program will cluster
n observations into gmin:gmax groups. If rowSums are zero,
these rows should be removed first.}

\item{membership}{A numeric vector of length nrow(dataset) containing the
cluster membership of each observation. If not available,
leave as "none". Default is "none".}

\item{gmin}{A positive integer specifying the minimum number of components
to be considered in the clustering run. Default is 1.}

\item{gmax}{A positive integer, >= gmin, specifying the maximum number of
components to be considered in the clustering run. Default is 3.}

\item{pmin}{A positive integer specifying the minimum number of latent
factors to be considered in the clustering run. Default is 1.}

\item{pmax}{A positive integer, >= pmin, specifying the maximum number of
latent factors to be considered in the clustering run. Default is 2.}

\item{initMethod}{A character vector indicating the initialization method
to be used. Default is "kmeans". Options are currently "kmeans" only.}

\item{modelNames}{A character string indicating the model names to test for
covariance matrix, Sigma. Since the largest contribution of free parameters
is through the covariance matrices, it is the focus for introduction
of parsimony. The constraints can be imposed on Lambda (loading matrix)
and Psi (error variance and isotropic) which are used to generate Sigma.
The 'C' stands for constrained and 'U' stands for unconstrained. The order
goes as loading matrix (Lambda), error variance (Psi) and isotropic (Psi),
respectively. Example, if the loading matrix (Lambda), error variance (Psi)
and isotropic are all constrained, then select "CCC". Options are "CCC",
"UUU", and "UCC". Default is "CCC".}

\item{normalize}{A string with options "Yes" or "No" specifying
if normalization should be performed. Currently, normalization factors
are calculated using TMM method of edgeR package. Default is "Yes".}
}
\value{
Returns an S3 object of class mixMPLNFA with results.
\itemize{
\item dataset - The input dataset on which clustering is performed.
\item dimensionality - Dimensionality of the input dataset.
\item normalizationFactors - A vector of normalization factors used
for input dataset.
\item gmin - Minimum number of components/clusters considered in the clustering
run.
\item gmax - Maximum number of components/clusters considered in the clustering
run.
\item pmin - Minimum number of latent factors (p) considered in the clustering
run.
\item pmax - Maximum number of latent factors (p) considered in the clustering
run.
\item allResults - A list with all results. To access results use the format
of 'g, p, model', respectively. See examples.
\item logLikelihood - A vector with value of final log-likelihoods for
each component/cluster size.
\item numbParameters - A vector with number of parameters for each
component/cluster size.
\item trueLabels - The vector of true labels, if provided by user.
\item ICLresults - A list with all ICL model selection results.
\item BICresults - A list with all BIC model selection results.
\item AICresults - A list with all AIC model selection results.
\item AIC3results - A list with all AIC3 model selection results.
\item totalTime - Total time used for clustering and model selection.
}
}
\description{
Performs simultaneous clustering and factor analysis using
parsimonious mixtures of multivariate Poisson-log
normal factor analyzers family (PMPLNFA) via
variational Gaussian approximations. Model selection can
be done using AIC, AIC3, BIC and ICL. In the PMPLNFA framework
restrictions are introduced to the model parameters with the
aim of obtaining parsimonious models, which are sufficiently
flexible for clustering purposes. Since the largest contribution
of free parameters is through the covariance matrices, it is
the focus for introduction of parsimony here. The constraints can
be imposed on Lambda (loading matrix) and Psi (error variance and
isotropic) which are used to generate Sigma. This function
simultaneously performs factor analysis and cluster analysis, by
assuming that the discrete observed data (counts) have been generated
by a factor analyzer model with continuous latent variables.
}
\details{
Starting values (argument: initMethod) play an
important role in the successful operation of this algorithm.
}
\examples{
# Example 1: Cluster a UCC datset
# Here, Lambda (loading matrix) is unconstrained and Psi
# (error variance and isotropic) are all constrained and
# hence UCC model is used

set.seed(100)
pfactors <- 2 # number of true latent factors
dimensionality <- 8 # dimensionality of observed data
trueClusters <- 4 # number of groups/clusters
mixingProportions <- c(0.11, 0.43, 0.24, 0.22) # mixing proportions for 4 clusters
nObservations <- 1000 # sample size or number of observations

# set parameter values
mu <- list(c(6, 3, 3, 6, 3, 6, 3, 3),
           c(5, 3, 5, 3, 5, 3, 3, 5),
           c(4, 2, 6, 4, 2, 6, 4, 4),
           c(1, 3, 5, 1, 3, 5, 3, 5))

Lambda <- list(matrix(runif(pfactors * dimensionality, -1, 1), nrow = dimensionality),
               matrix(runif(pfactors * dimensionality, -1, 1), nrow = dimensionality),
               matrix(runif(pfactors * dimensionality, -1, 1), nrow = dimensionality),
               matrix(runif(pfactors * dimensionality, -1, 1), nrow = dimensionality))

Psi <- list(diag(dimensionality) * runif(1),
            diag(dimensionality) * runif(1),
            diag(dimensionality) * runif(1),
            diag(dimensionality) * runif(1))

# generate datasets
simDataUCC <- mixMPLNFA::mplnFADataGenerator(numDatasets = 1,
                                             nObservations = nObservations,
                                             dimensionality = dimensionality,
                                             mixingProportions = mixingProportions,
                                             trueClusters = trueClusters,
                                             pfactors = pfactors,
                                             modelName = "UCC",
                                             mu = mu,
                                             Lambda = Lambda,
                                             Psi = Psi)

# Clustering
MPLNFAEx1 <- mixMPLNFA::MPLNFAClust(
  dataset = simDataUCC$`dataset=1`$dataset,
  membership = simDataUCC$`dataset=1`$trueMembership,
  gmin = 1,
  gmax = 4,
  pmin = 1,
  pmax = 3,
  modelNames = c("UUU", "UUC", "UCU", "UCC", "CUU", "CUC", "CCU", "CCC"),
  normalize = "Yes")

# To see BIC results
MPLNFAEx1$BICresults
MPLNFAEx1$BICresults$BICmodelselected

# Compare with true labels
table(MPLNFAEx1$BICresults$BICmodelSelectedLabels,
      simDataUCC$`dataset=1`$trueMembership)

# Access all results for g = 4, p = 2, model = "UCC"
# UCC is mentioned in fourth place for input string of modelNames argument
MPLNFAEx1$allResults[[4]][[2]][[4]]


# Example 2
# First generate a dataset from CCC model
# Here, Lambda (loading matrix) and Psi (error variance and
# isotropic) are all constrained and hence CCC

set.seed(100)
pfactors <- 3 # number of true latent factors
dimensionality <- 10 # dimensionality of observed data
trueClusters <- 2 # number of groups/clusters
mixingProportions <- c(0.32, 0.68) # mixing proportions for 2 clusters
nObservations <- 1000 # sample size or number of observations

# set parameter values
mu <- list(c(6, 3, 3, 6, 3, 6, 3, 3, 6 ,3),
           c(5, 3, 5, 3, 5, 5, 3, 5, 3, 5))

Lambda <- list(matrix(runif(pfactors * dimensionality, -1, 1), nrow = dimensionality),
               matrix(runif(pfactors * dimensionality, -1, 1), nrow = dimensionality))

Psi <- list(diag(dimensionality) * runif(1),
            diag(dimensionality) * runif(1))

# generate  a dataset
simDataCCC <- mixMPLNFA::mplnFADataGenerator(numDatasets = 1,
                                  nObservations = nObservations,
                                  dimensionality = dimensionality,
                                  mixingProportions = mixingProportions,
                                  trueClusters = trueClusters,
                                  pfactors = pfactors,
                                  modelName = "CCC",
                                  mu = mu,
                                  Lambda = Lambda,
                                  Psi = Psi)

dim(simDataCCC$`dataset=1`$dataset) # a dataset of size 1000 by 10

# Clustering
MPLNFAEx2 <- mixMPLNFA::MPLNFAClust(
                     dataset = simDataCCC$`dataset=1`$dataset,
                     membership = simDataCCC$`dataset=1`$trueMembership,
                     gmin = 1,
                     gmax = 2,
                     pmin = 1,
                     pmax = 3,
                     modelNames = c("UUU", "UUC", "UCU", "UCC", "CUU", "CUC", "CCU", "CCC"),
                     normalize = "No")

names(MPLNFAEx2) # see all names of outputs

# To see BIC results
MPLNFAEx2$BICresults
MPLNFAEx2$BICresults$BICmodelselected

# Compare with true labels
table(MPLNFAEx2$BICresults$BICmodelSelectedLabels,
      simDataCCC$`dataset=1`$trueMembership)

# Access all results for g = 2, p = 2, model = "CCC"
# CCC is mentioned in last place (8th) for input string of modelNames argument


# Example 3
# Here, Lambda (loading matrix) is unconstrained and Psi
(error variance and isotropic) are all unconstrained and
hence UUU model is used

set.seed(100)
pfactors <- 4 # number of true latent factors
dimensionality <- 10 # dimensionality of observed data
trueClusters <- 3 # number of groups/clusters
mixingProportions <- c(0.23, 0.44, 0.33) # mixing proportions for 4 clusters
nObservations <- 1000 # sample size or number of observations

# set parameter values
mu <- list(c(4, 6, 4, 2, 2, 4, 6, 4, 6, 2),
           c(5, 5, 3, 3, 7, 5, 3, 3, 7, 7),
           c(2, 4, 4, 7, 2, 4, 7, 2, 7, 4))

Lambda <- list(matrix(runif(pfactors * dimensionality, -1, 1), nrow = dimensionality),
               matrix(runif(pfactors * dimensionality, -1, 1), nrow = dimensionality),
               matrix(runif(pfactors * dimensionality, -1, 1), nrow = dimensionality))

Psi <- list(diag(dimensionality) * runif(dimensionality),
            diag(dimensionality) * runif(dimensionality),
            diag(dimensionality) * runif(dimensionality))

# generate datasets
simDataUUU <- mixMPLNFA::mplnFADataGenerator(numDatasets = 1,
                                  nObservations = nObservations,
                                  dimensionality = dimensionality,
                                  mixingProportions = mixingProportions,
                                  trueClusters = trueClusters,
                                  pfactors = pfactors,
                                  modelName = "UUU",
                                  mu = mu,
                                  Lambda = Lambda,
                                  Psi = Psi)

# Clustering
MPLNFAEx3 <- mixMPLNFA::MPLNFAClust(
                     dataset = simDataUUU$`dataset=1`$dataset,
                     membership = simDataUUU$`dataset=1`$trueMembership,
                     gmin = 1,
                     gmax = 2,
                     pmin = 1,
                     pmax = 3,
                     modelNames = c("UUU", "UUC", "UCU", "UCC", "CUU", "CUC", "CCU", "CCC"),
                     normalize = "No")

names(MPLNFAEx3) # see all names of outputs

# To see BIC results
MPLNFAEx3$BICresults
MPLNFAEx3$BICresults$BICmodelselected


}
\references{
Aitchison, J. and C. H. Ho (1989). The multivariate Poisson-log normal distribution.
\emph{Biometrika} 76.

Akaike, H. (1973). Information theory and an extension of the maximum likelihood
principle. In \emph{Second International Symposium on Information Theory}, New York, NY,
USA, pp. 267–281. Springer Verlag.

Arlot, S., Brault, V., Baudry, J., Maugis, C., and Michel, B. (2016).
capushe: CAlibrating Penalities Using Slope HEuristics. R package version 1.1.1.

Biernacki, C., G. Celeux, and G. Govaert (2000). Assessing a mixture model for
clustering with the integrated classification likelihood. \emph{IEEE Transactions
on Pattern Analysis and Machine Intelligence} 22.

Bozdogan, H. (1994). Mixture-model cluster analysis using model selection criteria
and a new informational measure of complexity. In \emph{Proceedings of the First US/Japan
Conference on the Frontiers of Statistical Modeling: An Informational Approach:
Volume 2 Multivariate Statistical Modeling}, pp. 69–113. Dordrecht: Springer Netherlands.

Robinson, M.D., and Oshlack, A. (2010). A scaling normalization method for differential
expression analysis of RNA-seq data. \emph{Genome Biology} 11, R25.

Schwarz, G. (1978). Estimating the dimension of a model. \emph{The Annals of Statistics}
6.

Silva, A. et al. (2019). A multivariate Poisson-log normal mixture model
for clustering transcriptome sequencing data. \emph{BMC Bioinformatics} 20.
\href{https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2916-0}{Link}
}
\author{
{Anjali Silva, \email{anjali@alumni.uoguelph.ca}, Andrea Payne, \email{andreapayne@cmail.carleton.ca},
Sanjeena Dang, \email{sanjeenadang@cunet.carleton.ca}. }
}
