% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mplnFAVisualize.R
\name{mplnFAVisLine}
\alias{mplnFAVisLine}
\title{Visualize Clustered Results Via Line Plots}
\usage{
mplnFAVisLine(
  dataset,
  clusterMembershipVector = NA,
  fileName = paste0("Plot_", date()),
  LinePlotColours = "black",
  printPlot = TRUE,
  format = "pdf"
)
}
\arguments{
\item{dataset}{A dataset of class matrix and type integer such that
rows correspond to observations and columns correspond to variables.}

\item{clusterMembershipVector}{A numeric vector of length nrow(dataset)
containing the cluster membership of each observation. If not provided,
all observations will be treated as belonging to one cluster. Default is NA.}

\item{fileName}{Unique character string indicating the name for the plot
being generated. Default is Plot_date, where date is obtained from
date().}

\item{LinePlotColours}{Character string indicating if the line plots
should be multicoloured or monotone, in black. Options are
'multicolour' or 'black'. Default is 'black'.}

\item{printPlot}{Logical indicating if plot(s) should be saved in local
directory. Default TRUE. Options TRUE or FALSE.}

\item{format}{Character string indicating the format of the image to
be produced. Default 'pdf'. Options 'pdf' or 'png'.}
}
\value{
Plotting function provides the possibility for line plots.
}
\description{
A function to visualize clustering results via line plots.
Each cluster will have its own plot. Data is log-transformed
prior to visualizing. Values for each sample are connected
by dashed lines to illustrate the trends (log counts). The
yellow line shows the mean value (log counts) for each cluster.
}
\examples{
# Example 1
trueMu1 <- c(6.5, 6, 6, 6, 6, 6, 6, 6, 6)
trueMu2 <- c(2, 2.5, 2, 2, 2, 2, 2, 2, 2)
trueMu3 <- c(1, 1, 1, 1, 1, 1, 1, 1, 1)

trueSigma1 <- diag(length(trueMu1)) * 2
trueSigma2 <- diag(length(trueMu1)) * 0.05
trueSigma3 <- diag(length(trueMu1)) * 0.01

# Generating simulated data with 3 clusters
sampleData <- MPLNClust::mplnDataGenerator(nObservations = 2000,
                     dimensionality = length(trueMu1),
                     mixingProportions = c(0.2, 0.3, 0.5),
                     mu = rbind(trueMu1, trueMu2, trueMu3),
                     sigma = rbind(trueSigma1, trueSigma2, trueSigma3),
                     produceImage = "No")

 dim(sampleData$dataset) # a dataset of size 2000 by 9

# Clustering
MPLNFAResults <- mixMPLNFA::MPLNFAClust(
                     dataset = sampleData$dataset,
                     membership = sampleData$trueMembership,
                     gmin = 1,
                     gmax = 4,
                     pmin = 1,
                     pmax = 1,
                     modelNames = c("CCU", "UUU"),
                     normalize = "Yes")

 # Visualize data using line plot
 # Use navigation buttons to see previous plots
 MPLNFABlack <- mixMPLNFA::mplnFAVisLine(dataset = sampleData$dataset,
                                         clusterMembershipVector =
                                         MPLNFAResults$BICresults$BICmodelSelectedLabels,
                                         fileName = 'Example1',
                                         printPlot = FALSE)


 # Visualize data using line plot with multicolours
 # Use navigation buttons to see previous plots
 MPLNLineColor <- mixMPLNFA::mplnFAVisLine(dataset = sampleData$dataset,
                                         clusterMembershipVector =
                                         MPLNFAResults$BICresults$BICmodelSelectedLabels,
                                         fileName = 'Example1MultiColor',
                                         LinePlotColours = "multicolour",
                                         printPlot = FALSE)

 # Example 2
trueMu1 <- c(6.5, 6, 6, 6, 6, 6, 6, 6, 6)
trueMu2 <- c(1, 2.5, 2, 2, 2, 2, 1, 1, 1)

trueSigma1 <- diag(length(trueMu1)) * 2.5
trueSigma2 <- diag(length(trueMu1)) * 0.5

# Generating simulated data with 2 clusters
sampleData2 <- MPLNClust::mplnDataGenerator(nObservations = 2000,
                     dimensionality = length(trueMu1),
                     mixingProportions = c(0.6, 0.4),
                     mu = rbind(trueMu1, trueMu2),
                     sigma = rbind(trueSigma1, trueSigma2),
                     produceImage = "No")

 dim(sampleData2$dataset) # a dataset of size 2000 by 9

# Clustering
MPLNFAResults2 <- mixMPLNFA::MPLNFAClust(
                     dataset = sampleData2$dataset,
                     membership = sampleData2$trueMembership,
                     gmin = 1,
                     gmax = 3,
                     pmin = 1,
                     pmax = 2,
                     modelNames = c("CCU"),
                     normalize = "Yes")

 # Visualize data using line plot with multicolours
 # Use navigation buttons to see previous plots
 MPLNLineColor <- mixMPLNFA::mplnFAVisLine(dataset = sampleData2$dataset,
                                         clusterMembershipVector =
                                         MPLNFAResults2$BICresults$BICmodelSelectedLabels,
                                         fileName = 'TwoClusterModel',
                                         LinePlotColours = "multicolour",
                                         printPlot = FALSE)


}
\references{
Aitchison, J. and C. H. Ho (1989). The multivariate Poisson-log normal distribution.
\emph{Biometrika} 76.

Akaike, H. (1973). Information theory and an extension of the maximum likelihood
principle. In \emph{Second International Symposium on Information Theory}, New York, NY,
USA, pp. 267–281. Springer Verlag.

Biernacki, C., G. Celeux, and G. Govaert (2000). Assessing a mixture model for
clustering with the integrated classification likelihood. \emph{IEEE Transactions
on Pattern Analysis and Machine Intelligence} 22.

Bozdogan, H. (1994). Mixture-model cluster analysis using model selection criteria
and a new informational measure of complexity. In \emph{Proceedings of the First US/Japan
Conference on the Frontiers of Statistical Modeling: An Informational Approach:
Volume 2 Multivariate Statistical Modeling}, pp. 69–113. Dordrecht: Springer Netherlands.

Ghahramani, Z., G. E. Hinton, et al. (1996). The EM algorithm for mixtures of
factor analyzers. Technical report, Technical Report CRG-TR-96-1, University
of Toronto.

Ghahramani, Z. and Beal, M. (1999). Variational inference for bayesian
mixtures of factor analysers. \emph{Advances in neural information processing
systems} 12.

Robinson, M.D., and Oshlack, A. (2010). A scaling normalization method for differential
expression analysis of RNA-seq data. \emph{Genome Biology} 11, R25.

Schwarz, G. (1978). Estimating the dimension of a model. \emph{The Annals of Statistics}
6.

Spearman, C. (1904). The proof and measurement of association between two things.
\emph{The American Journal of Psychology}, 15(1).

Silva, A. et al. (2019). A multivariate Poisson-log normal mixture model
for clustering transcriptome sequencing data. \emph{BMC Bioinformatics} 20.
\href{https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2916-0}{Link}

Silva, A., Qin, X., S. J. Rothstein, P. D. McNicholas, and S. Subedi (2023).
Finite mixtures of matrix variate Poisson-log normal distributions
for three-way count data, \emph{Bioinformatics} 39(5).
\href{https://doi.org/10.1093/bioinformatics/btad167}{Link}

Subedi, S., R.P. Browne (2020). A family of parsimonious mixtures of
multivariate Poisson-lognormal distributions for clustering multivariate
count data. \emph{Stat} 9:e310. \href{https://doi.org/10.1002/sta4.310}{Link}
}
\author{
Anjali Silva, \email{anjali@alumni.uoguelph.ca}
}
